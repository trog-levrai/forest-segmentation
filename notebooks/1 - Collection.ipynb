{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n",
    "\n",
    "In this notebook we will collect the raw data from sentinel2 satellite and the target data from the CORINE data.\n",
    "\n",
    "## Sentinel 2\n",
    "\n",
    "The sentinel2 data is available [here](https://scihub.copernicus.eu/). This program provides free multi spectral satellite imagery of the whole planet with a refresh rate of 3 to 5 days.\n",
    "\n",
    "The resolution depends on the band you are interested in, the highest being 10m and lowets being 60m.\n",
    "\n",
    "In this notebook, we will use the [`sentinelsat`](https://sentinelsat.readthedocs.io/en/stable/) library to select and download our data. You will need a free [account](https://scihub.copernicus.eu/userguide/SelfRegistration) for that.\n",
    "\n",
    "## CORINE\n",
    "\n",
    "The CORINE program is also a European program is a manual classification of the land cover in Europe. We will be using here the 2018 update as it is the latest and as we have sentinel data for this year.\n",
    "\n",
    "The data used is available [here](https://land.copernicus.eu/pan-european/corine-land-cover/clc2018) by going to the download tab and selecting the geoTiff. (You'll need a free account for that).\n",
    "\n",
    "The classification contains 44 classes that you can find [here](https://land.copernicus.eu/eagle/files/eagle-related-projects/pt_clc-conversion-to-fao-lccs3_dec2010). Classes are grouped into 5 main categories:\n",
    "* Artificial surfaces\n",
    "* Agriculture area\n",
    "* Forest and semi natural area\n",
    "* Wetlands\n",
    "* Water bodies\n",
    "\n",
    "In the following notebooks, we will be interested in all kinds of forests, classes `311`, `312` ad `313`.\n",
    "\n",
    "In the following, we assume the data is stored in the `data/` folder. We also need to have a geometry available. If you do not like the default one, you can create one on [geojson.io](http://geojson.io/). This geometry will be used to search for tiles to download.\n",
    "\n",
    "We use here an approximate version of Normandy's Geometry as I like this region :p\n",
    "You do not need to have a super accurate geometry at this step as this geometry is only used to query input data from the sentinel satellites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 results found\n"
     ]
    }
   ],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# First we connect to the Copernicus public API\n",
    "api = SentinelAPI(os.environ['DHUS_USER'], os.environ['DHUS_PASSWORD'])\n",
    "\n",
    "# Then we load the geometry to query the data\n",
    "footprint = geojson_to_wkt(read_geojson('../data/region.geojson'))\n",
    "\n",
    "# We query Coppernicus for 2020 as 2018 is archived and harder to retrieve.\n",
    "# We focus on June as this month has less clouds\n",
    "# Here we chose data between June because it is less likely to have clouds\n",
    "products = api.query(footprint,\n",
    "                     date=('20200601', '20200630'),\n",
    "                     producttype='S2MSI2A', # This is the athmosperic corrected version of S2\n",
    "                     cloudcoverpercentage=(0, 5))\n",
    "                     \n",
    "print(f'{len(products)} results found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you kept the default parameters you should see 31 tiles covering Normandy with less than 5% cloud coverage in June 2020. Let us now download these to the data folder. (Might take a while, so obviously try to run it only once).\n",
    "\n",
    "We also unzip them and delete the tarball for more convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/s2a/'\n",
    "api.download_all(products, raw_data_path)\n",
    "\n",
    "for tarball in os.listdir(raw_data_path):\n",
    "    path = os.path.join(raw_data_path, tarball)\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(raw_data_path)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this tutorial is now over, you can go check notebook 2 on pre-processing for the following."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
